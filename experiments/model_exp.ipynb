{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Adjust the import path based on your project structure\n",
    "# This assumes 'tests' is at the same level as 'models'\n",
    "from models.llama.config import ModelConfig\n",
    "\n",
    "def small_model_config_dir(tmp_path: Path) -> str:\n",
    "    \"\"\"\n",
    "    Creates a temporary directory with a config.json for a small model.\n",
    "    Returns the path to the directory as a string.\n",
    "    \"\"\"\n",
    "    config_data = {\n",
    "        \"hidden_size\": 64,\n",
    "        \"num_hidden_layers\": 2,\n",
    "        \"num_attention_heads\": 4,\n",
    "        \"num_key_value_heads\": 2,\n",
    "        \"intermediate_size\": 128,\n",
    "        \"vocab_size\": 1000,\n",
    "        \"rms_norm_eps\": 1e-6,\n",
    "        \"rope_theta\": 1000.0,\n",
    "        \"max_position_embeddings\": 512,\n",
    "        \"hidden_act\": \"silu\"\n",
    "    }\n",
    "    \n",
    "    config_path = tmp_path / \"config.json\"\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config_data, f)\n",
    "        \n",
    "    return str(tmp_path)\n",
    "\n",
    "def test_model_config_loading(small_model_config_dir: str):\n",
    "    \"\"\"\n",
    "    Tests loading a model configuration from a JSON file.\n",
    "    \"\"\"\n",
    "    # Load the configuration using the class method\n",
    "    config = ModelConfig.from_json_file(small_model_config_dir)\n",
    "\n",
    "    # Assert that all attributes are loaded correctly\n",
    "    assert config.dim == 64\n",
    "    assert config.n_layers == 2\n",
    "    assert config.n_heads == 4\n",
    "    assert config.n_kv_heads == 2\n",
    "    assert config.ffn_hidden_dim == 128\n",
    "    assert config.vocab_size == 1000\n",
    "    assert config.rms_norm_eps == 1e-6\n",
    "    assert config.rope_theta == 1000.0\n",
    "    assert config.max_seq_len == 512\n",
    "    assert config.activation_fn == \"silu\"\n",
    "\n",
    "    # Assert that the calculated property is correct\n",
    "    assert config.head_dim == 16 # (64 / 4)\n",
    "\n",
    "def test_gqa_validation():\n",
    "    \"\"\"\n",
    "    Tests that the GQA constraint (n_heads % n_kv_heads == 0) is enforced.\n",
    "    \"\"\"\n",
    "    with pytest.raises(ValueError, match=\"must be divisible by\"):\n",
    "        # This configuration is invalid and should raise an error\n",
    "        ModelConfig(n_heads=5, n_kv_heads=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig.from_json_file(\"/Users/ammar3.shaikh/Desktop/ReLax/experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.llama.config import ModelConfig\n",
    "from models.llama.model import LLaMA\n",
    "from utils.kvcache import KVCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LLaMA(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mul got incompatible shapes for broadcasting: (1, 10, 2, 8), (1, 10, 4, 8).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m start_pos = \u001b[32m0\u001b[39m\n\u001b[32m      5\u001b[39m kvcache = KVCache.new(n_layers=\u001b[32m2\u001b[39m, bsz=\u001b[32m1\u001b[39m, max_seq_len=\u001b[32m1024\u001b[39m, kv_heads=\u001b[32m2\u001b[39m, head_dim=\u001b[32m16\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m params = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkvcache\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 9 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ReLax/models/llama/model.py:96\u001b[39m, in \u001b[36mLLaMA.__call__\u001b[39m\u001b[34m(self, tokens, start_pos, kv_cache)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Transformer layers\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     h, kv_cache = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# Final normalization and output projection\u001b[39;00m\n\u001b[32m     99\u001b[39m h = rms_norm(h, \u001b[38;5;28mself\u001b[39m.norm_weight, eps=\u001b[38;5;28mself\u001b[39m.args.rms_norm_eps)\n",
      "    \u001b[31m[... skipping hidden 2 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ReLax/models/llama/model.py:35\u001b[39m, in \u001b[36mTransformerBlock.__call__\u001b[39m\u001b[34m(self, x, freqs_cis, kv_cache, layer_idx, start_pos)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: jax.Array, freqs_cis: jax.Array, kv_cache: KVCache, layer_idx: \u001b[38;5;28mint\u001b[39m, start_pos: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28mtuple\u001b[39m[jax.Array, KVCache]:\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Attention block\u001b[39;00m\n\u001b[32m     34\u001b[39m     h_norm = rms_norm(x, \u001b[38;5;28mself\u001b[39m.attention_norm_weight, eps=\u001b[38;5;28mself\u001b[39m.args.rms_norm_eps)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     attn_output, kv_cache = \u001b[43mgrouped_query_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mh_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_kv_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_kv_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     x = x + attn_output  \u001b[38;5;66;03m# Residual connection\u001b[39;00m\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# Feed-forward block\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ReLax/utils/ops.py:184\u001b[39m, in \u001b[36mgrouped_query_attention\u001b[39m\u001b[34m(x, freqs_cis, params, kv_cache, layer_idx, start_pos, n_heads, n_kv_heads)\u001b[39m\n\u001b[32m    179\u001b[39m current_freqs_cis = (\n\u001b[32m    180\u001b[39m     lax.dynamic_slice_in_dim(freqs_cis[\u001b[32m0\u001b[39m], start_pos, seqlen, axis=\u001b[32m0\u001b[39m),\n\u001b[32m    181\u001b[39m     lax.dynamic_slice_in_dim(freqs_cis[\u001b[32m1\u001b[39m], start_pos, seqlen, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    182\u001b[39m )\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# Pass the sliced freqs to RoPE\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m xq, xk = \u001b[43mapply_rotary_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_freqs_cis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# Update the KV cache\u001b[39;00m\n\u001b[32m    187\u001b[39m updated_cache = kv_cache.update(xk, xv, layer_idx, start_pos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ReLax/utils/ops.py:108\u001b[39m, in \u001b[36mapply_rotary_emb\u001b[39m\u001b[34m(xq, xk, freqs_cis)\u001b[39m\n\u001b[32m    106\u001b[39m xq_out_r = xq_r * freqs_cos - xq_i * freqs_sin\n\u001b[32m    107\u001b[39m xq_out_i = xq_r * freqs_sin + xq_i * freqs_cos\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m xk_out_r = \u001b[43mxk_r\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cos\u001b[49m - xk_i * freqs_sin\n\u001b[32m    109\u001b[39m xk_out_i = xk_r * freqs_sin + xk_i * freqs_cos\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# Combine back\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ReLax/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:583\u001b[39m, in \u001b[36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    581\u001b[39m args = (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ReLax/.venv/lib/python3.12/site-packages/jax/_src/numpy/ufunc_api.py:180\u001b[39m, in \u001b[36mufunc.__call__\u001b[39m\u001b[34m(self, out, where, *args)\u001b[39m\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhere argument of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    179\u001b[39m call = \u001b[38;5;28mself\u001b[39m.__static_props[\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_vectorized\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 14 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ReLax/.venv/lib/python3.12/site-packages/jax/_src/numpy/ufuncs.py:1280\u001b[39m, in \u001b[36mmultiply\u001b[39m\u001b[34m(x, y)\u001b[39m\n\u001b[32m   1254\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Multiply two arrays element-wise.\u001b[39;00m\n\u001b[32m   1255\u001b[39m \n\u001b[32m   1256\u001b[39m \u001b[33;03mJAX implementation of :obj:`numpy.multiply`. This is a universal function,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1277\u001b[39m \u001b[33;03m  Array([ 0, 10, 20, 30], dtype=int32)\u001b[39;00m\n\u001b[32m   1278\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1279\u001b[39m x, y = promote_args(\u001b[33m\"\u001b[39m\u001b[33mmultiply\u001b[39m\u001b[33m\"\u001b[39m, x, y)\n\u001b[32m-> \u001b[39m\u001b[32m1280\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m x.dtype != \u001b[38;5;28mbool\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m lax.bitwise_and(x, y)\n",
      "    \u001b[31m[... skipping hidden 10 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ReLax/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:135\u001b[39m, in \u001b[36m_try_broadcast_shapes\u001b[39m\u001b[34m(name, *shapes)\u001b[39m\n\u001b[32m    133\u001b[39m       result_shape.append(non_1s[\u001b[32m0\u001b[39m])\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m got incompatible shapes for broadcasting: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    136\u001b[39m                       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[31mTypeError\u001b[39m: mul got incompatible shapes for broadcasting: (1, 10, 2, 8), (1, 10, 4, 8)."
     ]
    }
   ],
   "source": [
    "import jax\n",
    "rng = jax.random.PRNGKey(0)\n",
    "tokens = jax.random.randint(rng, (1, 10), 0, 128256)\n",
    "start_pos = 0\n",
    "kvcache = KVCache.new(n_layers=2, bsz=1, max_seq_len=1024, kv_heads=2, head_dim=16)\n",
    "params = model.init(rng, tokens, start_pos, kvcache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No .safetensors files found in /Users/ammar3.shaikh/Desktop/ReLax/artifacts/weights",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m paths = \u001b[38;5;28mlist\u001b[39m(Path(model_path).glob(\u001b[33m'\u001b[39m\u001b[33m*.safetensors\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo .safetensors files found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filepath \u001b[38;5;129;01min\u001b[39;00m paths:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(filepath, framework=\u001b[33m\"\u001b[39m\u001b[33mflax\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mValueError\u001b[39m: No .safetensors files found in /Users/ammar3.shaikh/Desktop/ReLax/artifacts/weights"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from safetensors.flax import safe_open\n",
    "\n",
    "model_path = \"/Users/ammar3.shaikh/Desktop/ReLax/artifacts/weights\"\n",
    "paths = list(Path(model_path).glob('*.safetensors'))\n",
    "if not paths:\n",
    "    raise ValueError(f\"No .safetensors files found in {model_path}\")\n",
    "\n",
    "for filepath in paths:\n",
    "    with safe_open(filepath, framework=\"flax\") as f:\n",
    "        for key in f.keys():\n",
    "            print(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "@jax.jit\n",
    "def f(arr, x):\n",
    "    return arr[x]\n",
    "\n",
    "arr = jax.numpy.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(f(arr, 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(f(arr,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
