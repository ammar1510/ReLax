{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model.layers.20.input_layernorm.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.post_attention_layernorm.weight', 'model.layers.21.input_layernorm.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.post_attention_layernorm.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.input_layernorm.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.post_attention_layernorm.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.input_layernorm.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.post_attention_layernorm.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.input_layernorm.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.post_attention_layernorm.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.input_layernorm.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.post_attention_layernorm.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.input_layernorm.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.post_attention_layernorm.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.input_layernorm.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.post_attention_layernorm.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.norm.weight'])\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "# Load tensors from the file\n",
    "tensors = load_file(\"/Users/ammar3.shaikh/Desktop/ReLax/artifacts/weights/Llama-3.2-3B/model-00002-of-00002.safetensors\")\n",
    "\n",
    "# Inspect tensor keys\n",
    "print(tensors.keys())\n",
    "\n",
    "# Access a specific tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input string: '<|eot_id|>'\n",
      "Encoded IDs: [7, 8, 9, 10, 11, 8, 12]\n",
      "Decoded as token strings: ['<', '|', 'eot', '_', 'id', '|', '>']\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import base64\n",
    "\n",
    "# 1. Pattern string from your Tokenizer\n",
    "pat_str = r\"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+\"\n",
    "\n",
    "# 2. Dummy model vocabulary content (base64 token -> rank)\n",
    "\n",
    "    # A BPE ranks file where tokens align with pat_str behavior.\n",
    "    # \"token\"   -> dG9rZW4=\n",
    "    # \"1\"       -> MQ==\n",
    "    # \"2\"       -> Mg==\n",
    "    # \" \"       -> IA==\n",
    "    # \"b\"       -> Yg==\n",
    "    # \"c\"       -> Yw==\n",
    "    # \"a\"       -> YQ== (Corrected from ZQ==)\n",
    "    # \"<\"       -> PA==\n",
    "    # \"|\"       -> fA==\n",
    "    # \"eot\"     -> ZW90\n",
    "    # \"_\"       -> Xw==\n",
    "    # \"id\"      -> aWQ=\n",
    "    # \">\"       -> Pg==\n",
    "\n",
    "dummy_model_content = \"\"\"\n",
    "dG9rZW4= 0\n",
    "MQ== 1\n",
    "Mg== 2\n",
    "IA== 3\n",
    "Yg== 4\n",
    "Yw== 5\n",
    "YQ== 6\n",
    "PA== 7\n",
    "fA== 8\n",
    "ZW90 9\n",
    "Xw== 10\n",
    "aWQ= 11\n",
    "Pg== 12\n",
    "\"\"\"\n",
    "\n",
    "# 3. Create mergeable_ranks by decoding base64 tokens\n",
    "mergeable_ranks = {}\n",
    "for line in dummy_model_content.strip().split(\"\\n\"):\n",
    "    parts = line.split(\" \")\n",
    "    token_bytes_b64 = parts[0]\n",
    "    rank = int(parts[1])\n",
    "    mergeable_ranks[base64.b64decode(token_bytes_b64)] = rank\n",
    "\n",
    "# 4. Create a tiktoken.Encoding instance (no special tokens needed for this test)\n",
    "encoder = tiktoken.Encoding(\n",
    "    name=\"test_dummy_vocab\",\n",
    "    pat_str=pat_str,\n",
    "    mergeable_ranks=mergeable_ranks,\n",
    "    special_tokens={} # Empty because we use allowed_special=set()\n",
    ")\n",
    "\n",
    "# 5. The string to test\n",
    "test_string = \"<|eot_id|>\"\n",
    "\n",
    "# 6. Encode with allowed_special=set() to treat it as normal text\n",
    "encoded_ids = encoder.encode(test_string, allowed_special=set())\n",
    "\n",
    "print(f\"Input string: '{test_string}'\")\n",
    "print(f\"Encoded IDs: {encoded_ids}\")\n",
    "\n",
    "# Optional: decode each token ID back to see the string parts\n",
    "decoded_token_strings = [encoder.decode_single_token_bytes(token_id).decode('utf-8') for token_id in encoded_ids]\n",
    "print(f\"Decoded as token strings: {decoded_token_strings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "key = jax.random.PRNGKey(0)\n",
    "key1,key2,key3 = jax.random.split(key,3)\n",
    "\n",
    "A = jax.random.normal(key1, (3,4))\n",
    "B = jax.random.normal(key2, (4,5))\n",
    "C = jax.random.normal(key3, (3,4,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "D = jnp.einsum('ij,jk->ik',A,B)\n",
    "\n",
    "check_D = jnp.matmul(A,B)\n",
    "\n",
    "print(jnp.allclose(D,check_D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "E = jnp.einsum('ij,ij->ij',A,A)\n",
    "check_E = A*A\n",
    "\n",
    "print(jnp.allclose(E,check_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "F = jnp.einsum('ij->',A)\n",
    "check_F = jnp.sum(A)\n",
    "\n",
    "print(jnp.allclose(F,check_F))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "G = jnp.einsum('ij->j',A)\n",
    "check_G = jnp.sum(A,axis=0)\n",
    "\n",
    "print(jnp.allclose(G,check_G))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "H = jnp.einsum('ij->i',A)\n",
    "check_H = jnp.sum(A,axis=1)\n",
    "\n",
    "print(jnp.allclose(H,check_H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "I = jnp.einsum('ij->ji',A)\n",
    "check_I = A.T\n",
    "\n",
    "print(jnp.allclose(I,check_I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
