{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from models.llama.tokenizer import Tokenizer # Assumes tokenizer.py is in the same directory orPYTHONPATH\n",
    "os.environ[\"TIKTOKEN_CACHE_DIR\"] = \"\" # Add this line\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model_filename = \"dummy_custom_model.tiktoken\"\n",
    "\n",
    "    # A BPE ranks file where tokens align with pat_str behavior.\n",
    "    # \"token\"   -> dG9rZW4=\n",
    "    # \"1\"       -> MQ==\n",
    "    # \"2\"       -> Mg==\n",
    "    # \" \"       -> IA==\n",
    "    # \"b\"       -> Yg==\n",
    "    # \"c\"       -> Yw==\n",
    "    # \"a\"       -> YQ== \n",
    "    # \"e\"       -> ZQ==\n",
    "    # \"o\"       -> bw==\n",
    "    # \"t\"       -> dA==\n",
    "    # \"i\"       -> aQ==\n",
    "    # \"d\"       -> ZA==\n",
    "    # \"eo\"      -> ZW8=\n",
    "    # \"ot\"      -> b3Q=\n",
    "    # \"eot\"     -> ZW90\n",
    "    # \"<\"       -> PA==\n",
    "    # \"|\"       -> fA==\n",
    "    # \"_\"       -> Xw==\n",
    "    # \"id\"      -> aWQ=\n",
    "    # \">\"       -> Pg==\n",
    "dummy_model_content= \"\"\"\n",
    "dG9rZW4= 0\n",
    "MQ== 1\n",
    "Mg== 2\n",
    "IA== 3\n",
    "Yg== 4\n",
    "Yw== 5\n",
    "YQ== 6\n",
    "ZQ== 7\n",
    "bw== 8\n",
    "dA== 9\n",
    "aQ== 10\n",
    "ZA== 11\n",
    "ZW8= 12\n",
    "b3Q= 13\n",
    "ZW90 14\n",
    "PA== 15\n",
    "fA== 16\n",
    "Xw== 17\n",
    "aWQ= 18\n",
    "Pg== 19\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy tokenizer model: dummy_custom_model.tiktoken\n"
     ]
    }
   ],
   "source": [
    "processed_content = dummy_model_content.strip()\n",
    "\n",
    "with open(dummy_model_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(processed_content)\n",
    "print(f\"Created dummy tokenizer model: {dummy_model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing tokenizer with dummy model...\n",
      "{b'token': 0, b'1': 1, b'2': 2, b' ': 3, b'b': 4, b'c': 5, b'a': 6, b'e': 7, b'o': 8, b't': 9, b'i': 10, b'd': 11, b'eo': 12, b'ot': 13, b'eot': 14, b'<': 15, b'|': 16, b'_': 17, b'id': 18, b'>': 19}\n",
      "Tokenizer initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Initialize the Tokenizer\n",
    "# Note: The Tokenizer class defines its own special tokens like <|eot_id|>,\n",
    "# which will be added on top of the base vocabulary from the dummy file.\n",
    "print(\"\\nInitializing tokenizer with dummy model...\")\n",
    "tokenizer = Tokenizer(model_path=dummy_model_filename)\n",
    "print(\"Tokenizer initialized successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'ZA=='\n"
     ]
    }
   ],
   "source": [
    "print(base64.b64encode(b\"d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_token_str = \"<|eot_id|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_tokens_for_disallowed_special = [13, 14, 12, 15, 16, 17]\n",
    "actual_tokens = tokenizer.encode(special_token_str, bos=False, eos=False, allowed_special=set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 16, 14, 17, 18, 16, 19]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
