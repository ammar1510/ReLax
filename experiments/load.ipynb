{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from models.llama.model import LLaMa\n",
    "from models.llama.config import ModelConfig\n",
    "from utils.kvcache import KVCache\n",
    "from models.llama.load import load_llama_weights, pth_to_safetensors\n",
    "from utils.memory import estimate_pytree_memory_footprint, format_bytes\n",
    "from models.llama.tokenizer import Tokenizer\n",
    "from sampling import Sampler\n",
    "from sampling import TopPSampler\n",
    "\n",
    "devices = jax.devices()\n",
    "jax.config.update(\"jax_default_matmul_precision\", \"highest\")\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/ammar3.shaikh/ReLax/artifacts/weights/Llama-3.2-3B-JAX/model.safetensors\"\n",
    "max_seqlen = 2048\n",
    "\n",
    "model_config = ModelConfig.from_json_file(\"/home/ammar3.shaikh/ReLax/artifacts/weights/Llama-3.2-3B-JAX\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig(vocab_size=128256, dim=3072, ffn_hidden_dim=8192, n_layers=28, n_heads=24, n_kv_heads=8, activation_fn='silu', max_seqlen=8192, rope_theta=500000.0, rms_norm_eps=1e-05, mode='inference', dtype='float32', use_scaled_rope=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_llama_weights(model_path, model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13.44GB'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To inspect the PyTree, you can print the shape of each leaf node (array).\n",
    "# This preserves the tree structure.\n",
    "param_shapes = jax.tree_util.tree_map(lambda x: x.shape, params)\n",
    "format_bytes(estimate_pytree_memory_footprint(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LLaMa(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.75GB'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JAX init\n",
    "key = jax.random.PRNGKey(0)\n",
    "batch_size = 1\n",
    "seq_len = 512\n",
    "dummy_tokens = jnp.ones((batch_size, seq_len), dtype=jnp.int32)\n",
    "dummy_kvcache = KVCache.new(n_layers=model_config.n_layers, bsz=batch_size, max_seqlen=model_config.max_seqlen, kv_heads=model_config.n_kv_heads, head_dim=model_config.head_dim, dtype=model_config.dtype)\n",
    "\n",
    "format_bytes(estimate_pytree_memory_footprint(dummy_kvcache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.apply({\"params\":params}, dummy_tokens, 0, dummy_kvcache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to /home/ammar3.shaikh/ReLax/artifacts/weights/Llama-3.2-3B-JAX/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "output_path = \"/home/ammar3.shaikh/ReLax/artifacts/weights/Llama-3.2-3B-JAX\"\n",
    "pth_model_path = \"/home/ammar3.shaikh/ReLax/artifacts/weights/Llama-3.2-3B/original/consolidated.00.pth\"\n",
    "config_dir = \"/home/ammar3.shaikh/ReLax/artifacts/weights/Llama-3.2-3B/\"\n",
    "pth_to_safetensors(pth_model_path, config_dir, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tok_embeddings.weight', 'layers.0.attention.wq.weight', 'layers.0.attention.wk.weight', 'layers.0.attention.wv.weight', 'layers.0.attention.wo.weight', 'layers.0.feed_forward.w1.weight', 'layers.0.feed_forward.w3.weight', 'layers.0.feed_forward.w2.weight', 'layers.0.attention_norm.weight', 'layers.0.ffn_norm.weight', 'layers.1.attention.wq.weight', 'layers.1.attention.wk.weight', 'layers.1.attention.wv.weight', 'layers.1.attention.wo.weight', 'layers.1.feed_forward.w1.weight', 'layers.1.feed_forward.w3.weight', 'layers.1.feed_forward.w2.weight', 'layers.1.attention_norm.weight', 'layers.1.ffn_norm.weight', 'layers.2.attention.wq.weight', 'layers.2.attention.wk.weight', 'layers.2.attention.wv.weight', 'layers.2.attention.wo.weight', 'layers.2.feed_forward.w1.weight', 'layers.2.feed_forward.w3.weight', 'layers.2.feed_forward.w2.weight', 'layers.2.attention_norm.weight', 'layers.2.ffn_norm.weight', 'layers.3.attention.wq.weight', 'layers.3.attention.wk.weight', 'layers.3.attention.wv.weight', 'layers.3.attention.wo.weight', 'layers.3.feed_forward.w1.weight', 'layers.3.feed_forward.w3.weight', 'layers.3.feed_forward.w2.weight', 'layers.3.attention_norm.weight', 'layers.3.ffn_norm.weight', 'layers.4.attention.wq.weight', 'layers.4.attention.wk.weight', 'layers.4.attention.wv.weight', 'layers.4.attention.wo.weight', 'layers.4.feed_forward.w1.weight', 'layers.4.feed_forward.w3.weight', 'layers.4.feed_forward.w2.weight', 'layers.4.attention_norm.weight', 'layers.4.ffn_norm.weight', 'layers.5.attention.wq.weight', 'layers.5.attention.wk.weight', 'layers.5.attention.wv.weight', 'layers.5.attention.wo.weight', 'layers.5.feed_forward.w1.weight', 'layers.5.feed_forward.w3.weight', 'layers.5.feed_forward.w2.weight', 'layers.5.attention_norm.weight', 'layers.5.ffn_norm.weight', 'layers.6.attention.wq.weight', 'layers.6.attention.wk.weight', 'layers.6.attention.wv.weight', 'layers.6.attention.wo.weight', 'layers.6.feed_forward.w1.weight', 'layers.6.feed_forward.w3.weight', 'layers.6.feed_forward.w2.weight', 'layers.6.attention_norm.weight', 'layers.6.ffn_norm.weight', 'layers.7.attention.wq.weight', 'layers.7.attention.wk.weight', 'layers.7.attention.wv.weight', 'layers.7.attention.wo.weight', 'layers.7.feed_forward.w1.weight', 'layers.7.feed_forward.w3.weight', 'layers.7.feed_forward.w2.weight', 'layers.7.attention_norm.weight', 'layers.7.ffn_norm.weight', 'layers.8.attention.wq.weight', 'layers.8.attention.wk.weight', 'layers.8.attention.wv.weight', 'layers.8.attention.wo.weight', 'layers.8.feed_forward.w1.weight', 'layers.8.feed_forward.w3.weight', 'layers.8.feed_forward.w2.weight', 'layers.8.attention_norm.weight', 'layers.8.ffn_norm.weight', 'layers.9.attention.wq.weight', 'layers.9.attention.wk.weight', 'layers.9.attention.wv.weight', 'layers.9.attention.wo.weight', 'layers.9.feed_forward.w1.weight', 'layers.9.feed_forward.w3.weight', 'layers.9.feed_forward.w2.weight', 'layers.9.attention_norm.weight', 'layers.9.ffn_norm.weight', 'layers.10.attention.wq.weight', 'layers.10.attention.wk.weight', 'layers.10.attention.wv.weight', 'layers.10.attention.wo.weight', 'layers.10.feed_forward.w1.weight', 'layers.10.feed_forward.w3.weight', 'layers.10.feed_forward.w2.weight', 'layers.10.attention_norm.weight', 'layers.10.ffn_norm.weight', 'layers.11.attention.wq.weight', 'layers.11.attention.wk.weight', 'layers.11.attention.wv.weight', 'layers.11.attention.wo.weight', 'layers.11.feed_forward.w1.weight', 'layers.11.feed_forward.w3.weight', 'layers.11.feed_forward.w2.weight', 'layers.11.attention_norm.weight', 'layers.11.ffn_norm.weight', 'layers.12.attention.wq.weight', 'layers.12.attention.wk.weight', 'layers.12.attention.wv.weight', 'layers.12.attention.wo.weight', 'layers.12.feed_forward.w1.weight', 'layers.12.feed_forward.w3.weight', 'layers.12.feed_forward.w2.weight', 'layers.12.attention_norm.weight', 'layers.12.ffn_norm.weight', 'layers.13.attention.wq.weight', 'layers.13.attention.wk.weight', 'layers.13.attention.wv.weight', 'layers.13.attention.wo.weight', 'layers.13.feed_forward.w1.weight', 'layers.13.feed_forward.w3.weight', 'layers.13.feed_forward.w2.weight', 'layers.13.attention_norm.weight', 'layers.13.ffn_norm.weight', 'layers.14.attention.wq.weight', 'layers.14.attention.wk.weight', 'layers.14.attention.wv.weight', 'layers.14.attention.wo.weight', 'layers.14.feed_forward.w1.weight', 'layers.14.feed_forward.w3.weight', 'layers.14.feed_forward.w2.weight', 'layers.14.attention_norm.weight', 'layers.14.ffn_norm.weight', 'layers.15.attention.wq.weight', 'layers.15.attention.wk.weight', 'layers.15.attention.wv.weight', 'layers.15.attention.wo.weight', 'layers.15.feed_forward.w1.weight', 'layers.15.feed_forward.w3.weight', 'layers.15.feed_forward.w2.weight', 'layers.15.attention_norm.weight', 'layers.15.ffn_norm.weight', 'layers.16.attention.wq.weight', 'layers.16.attention.wk.weight', 'layers.16.attention.wv.weight', 'layers.16.attention.wo.weight', 'layers.16.feed_forward.w1.weight', 'layers.16.feed_forward.w3.weight', 'layers.16.feed_forward.w2.weight', 'layers.16.attention_norm.weight', 'layers.16.ffn_norm.weight', 'layers.17.attention.wq.weight', 'layers.17.attention.wk.weight', 'layers.17.attention.wv.weight', 'layers.17.attention.wo.weight', 'layers.17.feed_forward.w1.weight', 'layers.17.feed_forward.w3.weight', 'layers.17.feed_forward.w2.weight', 'layers.17.attention_norm.weight', 'layers.17.ffn_norm.weight', 'layers.18.attention.wq.weight', 'layers.18.attention.wk.weight', 'layers.18.attention.wv.weight', 'layers.18.attention.wo.weight', 'layers.18.feed_forward.w1.weight', 'layers.18.feed_forward.w3.weight', 'layers.18.feed_forward.w2.weight', 'layers.18.attention_norm.weight', 'layers.18.ffn_norm.weight', 'layers.19.attention.wq.weight', 'layers.19.attention.wk.weight', 'layers.19.attention.wv.weight', 'layers.19.attention.wo.weight', 'layers.19.feed_forward.w1.weight', 'layers.19.feed_forward.w3.weight', 'layers.19.feed_forward.w2.weight', 'layers.19.attention_norm.weight', 'layers.19.ffn_norm.weight', 'layers.20.attention.wq.weight', 'layers.20.attention.wk.weight', 'layers.20.attention.wv.weight', 'layers.20.attention.wo.weight', 'layers.20.feed_forward.w1.weight', 'layers.20.feed_forward.w3.weight', 'layers.20.feed_forward.w2.weight', 'layers.20.attention_norm.weight', 'layers.20.ffn_norm.weight', 'layers.21.attention.wq.weight', 'layers.21.attention.wk.weight', 'layers.21.attention.wv.weight', 'layers.21.attention.wo.weight', 'layers.21.feed_forward.w1.weight', 'layers.21.feed_forward.w3.weight', 'layers.21.feed_forward.w2.weight', 'layers.21.attention_norm.weight', 'layers.21.ffn_norm.weight', 'layers.22.attention.wq.weight', 'layers.22.attention.wk.weight', 'layers.22.attention.wv.weight', 'layers.22.attention.wo.weight', 'layers.22.feed_forward.w1.weight', 'layers.22.feed_forward.w3.weight', 'layers.22.feed_forward.w2.weight', 'layers.22.attention_norm.weight', 'layers.22.ffn_norm.weight', 'layers.23.attention.wq.weight', 'layers.23.attention.wk.weight', 'layers.23.attention.wv.weight', 'layers.23.attention.wo.weight', 'layers.23.feed_forward.w1.weight', 'layers.23.feed_forward.w3.weight', 'layers.23.feed_forward.w2.weight', 'layers.23.attention_norm.weight', 'layers.23.ffn_norm.weight', 'layers.24.attention.wq.weight', 'layers.24.attention.wk.weight', 'layers.24.attention.wv.weight', 'layers.24.attention.wo.weight', 'layers.24.feed_forward.w1.weight', 'layers.24.feed_forward.w3.weight', 'layers.24.feed_forward.w2.weight', 'layers.24.attention_norm.weight', 'layers.24.ffn_norm.weight', 'layers.25.attention.wq.weight', 'layers.25.attention.wk.weight', 'layers.25.attention.wv.weight', 'layers.25.attention.wo.weight', 'layers.25.feed_forward.w1.weight', 'layers.25.feed_forward.w3.weight', 'layers.25.feed_forward.w2.weight', 'layers.25.attention_norm.weight', 'layers.25.ffn_norm.weight', 'layers.26.attention.wq.weight', 'layers.26.attention.wk.weight', 'layers.26.attention.wv.weight', 'layers.26.attention.wo.weight', 'layers.26.feed_forward.w1.weight', 'layers.26.feed_forward.w3.weight', 'layers.26.feed_forward.w2.weight', 'layers.26.attention_norm.weight', 'layers.26.ffn_norm.weight', 'layers.27.attention.wq.weight', 'layers.27.attention.wk.weight', 'layers.27.attention.wv.weight', 'layers.27.attention.wo.weight', 'layers.27.feed_forward.w1.weight', 'layers.27.feed_forward.w3.weight', 'layers.27.feed_forward.w2.weight', 'layers.27.attention_norm.weight', 'layers.27.ffn_norm.weight', 'norm.weight', 'output.weight'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pth_model_path = \"/home/ammar3.shaikh/ReLax/artifacts/weights/Llama-3.2-3B/original/consolidated.00.pth\"\n",
    "tensors = torch.load(pth_model_path, map_location=\"cpu\")\n",
    "\n",
    "print(tensors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits,updated_kvcache = logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 128256)\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
