{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "931ac237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax.experimental import pallas as pl   \n",
    "from jax.experimental.pallas import tpu as pltpu\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "697c38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hbm_vmem_kernel(x_hbm_ref, out_vmem_ref, scratch_vmem_ref):\n",
    "  pltpu.sync_copy(x_hbm_ref.at[0:3], scratch_vmem_ref.at[0:3])\n",
    "  out_vmem_ref[...] = scratch_vmem_ref[...] + 1\n",
    "\n",
    "x = jax.random.uniform(jax.random.key(0), (8, 128), jnp.float32)\n",
    "out = pl.pallas_call(hbm_vmem_kernel,\n",
    "  in_specs=[pl.BlockSpec(memory_space=pltpu.MemorySpace.ANY)],\n",
    "  out_shape=jax.ShapeDtypeStruct((3, 128), jnp.float32),\n",
    "  scratch_shapes=(pltpu.MemorySpace.VMEM(shape=(3, 128), dtype=jnp.float32),)\n",
    ")(x)\n",
    "\n",
    "np.testing.assert_allclose(out, x[0:3] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43702d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matrices_kernel(x_vmem_ref, y_vmem_ref, out_vmem_ref):\n",
    "    x_vregs = x_vmem_ref[...]\n",
    "    y_vregs = y_vmem_ref[...]\n",
    "    out_vmem_ref[...] = x_vregs[...] + y_vregs[...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2926f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matrices(x:jax.Array,y:jax.Array)->jax.Array:\n",
    "    block_spec = pl.BlockSpec((256,512),lambda i:(i,0))\n",
    "    return pl.pallas_call(add_matrices_kernel,\n",
    "    out_shape=x,\n",
    "    in_specs=[block_spec,block_spec],\n",
    "    out_specs=block_spec,\n",
    "    grid=(2,),\n",
    "    compiler_params=pltpu.CompilerParams(\n",
    "        dimension_semantics=(\"parallel\",)\n",
    "    )\n",
    ")(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46ffa54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = jax.random.uniform(jax.random.key(0), (256,512), jnp.float32),jax.random.uniform(jax.random.key(42), (256,512), jnp.float32)\n",
    "\n",
    "\n",
    "out = add_matrices(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e43d63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapeDtypeStruct(shape=(256, 512), dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.ShapeDtypeStruct((256,512),jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214ad2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_small(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "  m, k, n = x.shape[0], x.shape[1], y.shape[0]\n",
    "  assert m <= 256\n",
    "  assert k <= 256\n",
    "  assert n <= 256\n",
    "  return np.matmul(x, y)\n",
    "\n",
    "def block_matmul(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    *,\n",
    "    bm: int = 256,\n",
    "    bk: int = 256,\n",
    "    bn: int = 256,\n",
    ") -> np.ndarray:\n",
    "  m, k = x.shape\n",
    "  _, n = y.shape\n",
    "\n",
    "  z = np.zeros((m, n), dtype=x.dtype)\n",
    "  for m_i in range(m // bm):\n",
    "    for n_i in range(n // bn):\n",
    "      for k_i in range(k // bk):\n",
    "        m_slice = slice(m_i * bm, (m_i + 1) * bm)\n",
    "        k_slice = slice(k_i * bk, (k_i + 1) * bk)\n",
    "        n_slice = slice(n_i * bn, (n_i + 1) * bn)\n",
    "        x_block = x[m_slice, k_slice]\n",
    "        y_block = y[k_slice, n_slice]\n",
    "        z[m_slice, n_slice] += matmul_small(x_block, y_block)\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a311c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2147483648\n",
      "12582912\n"
     ]
    }
   ],
   "source": [
    "def matmul_flops(m: int, k: int, n: int):\n",
    "  return 2 * m * k * n\n",
    "\n",
    "def matmul_membw(m: int, k: int, n: int, dtype: jnp.dtype):\n",
    "  return (m * k + k * n + m * n) * np.dtype(dtype).itemsize\n",
    "\n",
    "print(matmul_flops(1024, 1024, 1024))\n",
    "print(matmul_membw(1024, 1024, 1024, jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c28536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v5e_flops = 197e12\n",
    "v5e_membw = 819e9\n",
    "v5e_op_intensity = v5e_flops / v5e_membw  # ~240.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3398698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_flops_intensity(m: int, k: int, n: int, dtype: jnp.dtype):\n",
    "  flops = matmul_flops(m, k, n)\n",
    "  membw = matmul_membw(m, k, n, dtype)\n",
    "  return flops / membw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fdd4f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170.66666666666666 flops/byte\n"
     ]
    }
   ],
   "source": [
    "print(f\"{matmul_flops_intensity(1024, 1024, 1024, jnp.float32)} flops/byte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b92af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341.3333333333333 flops/byte\n"
     ]
    }
   ],
   "source": [
    "print(f\"{matmul_flops_intensity(1024, 1024, 1024, jnp.bfloat16)} flops/byte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "052c3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_kernel(x_ref,y_ref,z_ref,acc_ref,*,nsteps):\n",
    "    @pl.when(pl.program_id(2)==0)\n",
    "    def init():\n",
    "        acc_ref[...] = jnp.zeros_like(acc_ref)\n",
    "\n",
    "    acc_ref[...]+=jnp.dot(x_ref[...],y_ref[...],preferred_element_type=jnp.float32)\n",
    "    @pl.when(pl.program_id(2)==nsteps-1)\n",
    "    def final():\n",
    "        z_ref[...] = acc_ref[...].astype(x_ref.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb41bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(x:jax.Array,y:jax.Array,*,bm=128,bk=128,bn=128)->jax.Array:\n",
    "    m,k = x.shape\n",
    "    _,n = y.shape\n",
    "    assert m%bm==0 and k%bk==0 and n%bn==0\n",
    "    m_blocks = m//bm\n",
    "    k_blocks = k//bk\n",
    "    n_blocks = n//bn\n",
    "    return pl.pallas_call(functools.partial(matmul_kernel,nsteps=k_blocks),\n",
    "    grid_spec=pltpu.PrefetchScalarGridSpec(num_scalar_prefetch=0,\n",
    "    in_specs=[\n",
    "        pl.BlockSpec((bm,bk),lambda i,j,k:(i,k)),\n",
    "        pl.BlockSpec((bk,bn),lambda i,j,k:(k,j)),\n",
    "    ],\n",
    "    out_specs=pl.BlockSpec((bm,bn),lambda i,j,k:(i,j)),\n",
    "    scratch_shapes=[pltpu.MemorySpace.VMEM(shape=(bm,bk),dtype=jnp.float32)],\n",
    "    grid=(m_blocks,n_blocks,k_blocks),\n",
    "    ),\n",
    "    out_shape=jax.ShapeDtypeStruct((m,n),x.dtype),\n",
    "    compiler_params=pltpu.CompilerParams(\n",
    "        dimension_semantics=(\"parallel\",\"parallel\",\"arbitrary\")\n",
    "    ),\n",
    "    )(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6749ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n,k = 4096,4096,4096\n",
    "x = jax.random.normal(jax.random.key(0), (m,k), jnp.bfloat16)\n",
    "y = jax.random.normal(jax.random.key(0), (k,n), jnp.bfloat16)\n",
    "z = matmul(x,y)\n",
    "np.testing.assert_array_equal(z,x@y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d501a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfa228de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def f(x:jax.Array,y:jax.Array)->jax.Array:\n",
    "    return g(x)+y\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit,donate_argnums=[0])\n",
    "def g(x:jax.Array)->jax.Array:\n",
    "    return x+1\n",
    "\n",
    "x = jax.random.normal(jax.random.key(0), (1024,1024), jnp.float32)\n",
    "y = jax.random.normal(jax.random.key(0), (1024,1024), jnp.float32)\n",
    "z = f(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8ce8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Array has been deleted with shape=int32[1].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m     12\u001b[39m x = myClass(\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m y = \u001b[43mx\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(y)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mmyClass.__call__\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m      6\u001b[39m x = jnp.array([\u001b[32m1\u001b[39m])\n\u001b[32m      7\u001b[39m out = g(x)+y\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ReLax/.venv/lib/python3.12/site-packages/jax/_src/array.py:296\u001b[39m, in \u001b[36mArrayImpl.__str__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_value\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ReLax/.venv/lib/python3.12/site-packages/jax/_src/profiler.py:354\u001b[39m, in \u001b[36mannotate_function.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    353\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, **decorator_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ReLax/.venv/lib/python3.12/site-packages/jax/_src/array.py:639\u001b[39m, in \u001b[36mArrayImpl._value\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    636\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;129m@functools\u001b[39m.partial(profiler.annotate_function, name=\u001b[33m\"\u001b[39m\u001b[33mnp.asarray(jax.Array)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_value\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_if_deleted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    641\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._npy_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.is_fully_replicated \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    643\u001b[39m         \u001b[38;5;28mself\u001b[39m.sharding._internal_device_list.addressable_device_list):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ReLax/.venv/lib/python3.12/site-packages/jax/_src/array.py:608\u001b[39m, in \u001b[36mArrayImpl._check_if_deleted\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_if_deleted\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    607\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_deleted():\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    609\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mArray has been deleted with shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.aval.str_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Array has been deleted with shape=int32[1]."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class myClass:\n",
    "    def __init__(self,x:int):\n",
    "        self.x = x\n",
    "\n",
    "    def __call__(self,y:int)->int:\n",
    "        x = jnp.array([1])\n",
    "        out = g(x)+y\n",
    "        print(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "x = myClass(1)\n",
    "y = x(2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1dd0b9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "y = x(3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d803f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e89b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def precompute_freqs_cis_numpy(\n",
    "    dim: int, end: int, theta: float = 10000.0, use_scaled: bool = False, dtype=np.float32\n",
    "):\n",
    "    \"\"\"\n",
    "    NumPy equivalent of the precompute_freqs_cis torch function.\n",
    "    \"\"\"\n",
    "    # Note: If use_scaled is True, you will need to provide a NumPy\n",
    "    # implementation of the `apply_scaling` function.\n",
    "    if use_scaled:\n",
    "        raise NotImplementedError(\n",
    "            \"The `apply_scaling` function is not implemented for NumPy in this snippet.\"\n",
    "        )\n",
    "\n",
    "    # Calculate frequencies\n",
    "    freqs = 1.0 / (theta ** (np.arange(0, dim, 2).astype(dtype) / dim))\n",
    "\n",
    "    # Create the time sequence\n",
    "    t = np.arange(end, dtype=dtype)\n",
    "\n",
    "    # Compute the outer product to get phase angles for all positions and dimensions\n",
    "    freqs = np.outer(t, freqs)\n",
    "\n",
    "    # Convert phase angles to complex numbers on the unit circle\n",
    "    # e^(i*theta) = cos(theta) + i*sin(theta)\n",
    "    freqs_cis = np.exp(1j * freqs)\n",
    "\n",
    "    # Stack the real and imaginary parts to match the torch output shape\n",
    "    freqs_cis_real = np.stack([np.real(freqs_cis), np.imag(freqs_cis)], axis=-1)\n",
    "\n",
    "    return freqs_cis_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b45e6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.0001, atol=0.0001\n\nMismatched elements: 7639 / 131072 (5.83%)\nMax absolute difference among violations: 0.00213042\nMax relative difference among violations: 1.4310915\n ACTUAL: array([[[ 1.000000e+00,  0.000000e+00],\n        [ 1.000000e+00,  0.000000e+00],\n        [ 1.000000e+00,  0.000000e+00],...\n DESIRED: array([[[ 1.000000e+00,  0.000000e+00],\n        [ 1.000000e+00,  0.000000e+00],\n        [ 1.000000e+00,  0.000000e+00],...",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m freqs_cis_numpy = precompute_freqs_cis_numpy(\u001b[32m128\u001b[39m, \u001b[32m1024\u001b[39m, \u001b[32m500000.0\u001b[39m)\n\u001b[32m     13\u001b[39m freqs_cis_torch = precompute_freqs_cis_torch(\u001b[32m128\u001b[39m, \u001b[32m1024\u001b[39m, \u001b[32m500000.0\u001b[39m).to(dtype=torch.float32)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m.\u001b[49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreqs_cis_jax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis_numpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ReLax/.venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:926\u001b[39m, in \u001b[36massert_array_compare\u001b[39m\u001b[34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict, names)\u001b[39m\n\u001b[32m    921\u001b[39m         err_msg += \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m + \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m.join(remarks)\n\u001b[32m    922\u001b[39m         msg = build_err_msg([ox, oy], err_msg,\n\u001b[32m    923\u001b[39m                             verbose=verbose, header=header,\n\u001b[32m    924\u001b[39m                             names=names,\n\u001b[32m    925\u001b[39m                             precision=precision)\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m    928\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtraceback\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: \nNot equal to tolerance rtol=0.0001, atol=0.0001\n\nMismatched elements: 7639 / 131072 (5.83%)\nMax absolute difference among violations: 0.00213042\nMax relative difference among violations: 1.4310915\n ACTUAL: array([[[ 1.000000e+00,  0.000000e+00],\n        [ 1.000000e+00,  0.000000e+00],\n        [ 1.000000e+00,  0.000000e+00],...\n DESIRED: array([[[ 1.000000e+00,  0.000000e+00],\n        [ 1.000000e+00,  0.000000e+00],\n        [ 1.000000e+00,  0.000000e+00],..."
     ]
    }
   ],
   "source": [
    "from utils.ops import precompute_freqs_cis as precompute_freqs_cis_jax\n",
    "from experiments.torch_llama import precompute_freqs_cis as precompute_freqs_cis_torch\n",
    "import torch\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "jax.config.update(\"jax_default_matmul_precision\", \"highest\")\n",
    "\n",
    "\n",
    "freqs_cis_jax = precompute_freqs_cis_jax(128, 1024, 500000.0, dtype=jnp.bfloat16)\n",
    "freqs_cis_numpy = precompute_freqs_cis_numpy(128, 1024, 500000.0)\n",
    "freqs_cis_torch = precompute_freqs_cis_torch(128, 1024, 500000.0).to(dtype=torch.bfloat16)\n",
    "\n",
    "np.testing.assert_allclose(freqs_cis_jax, freqs_cis_numpy, rtol=1e-4, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b094ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(freqs_cis_numpy, freqs_cis_torch, rtol=1e-4, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb766fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
